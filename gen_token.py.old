import keyword
import string
from specialcharnames import *
from symbolnames import *

of = open("tokeniser.tex", "w")
of.write("\\newcount\\state\n")
of.write("\\state=0\n\n")

of.write("\\def\\buffer{}")
of.write("\\def\\tokenlist{}")


keyword_states = set()
for kw in keyword.kwlist:
    for i in range(len(kw)+1):
        keyword_states.add(kw[:i])

symbol_states = set()
for sym in symbolnames:
    for i in range(len(sym)+1):
        symbol_states.add(sym[:i])



states = list(keyword_states.union(symbol_states))



IDENTIFIER_STATE = len(states)
states.append("<IDENTIFIER_STATE>")

# TODO: comment state
# TODO: string state
# TODO: floats
NUMBER_STATE = len(states) # TODO: handle number state and comment state properly everywhere
states.append("<NUMBER_STATE>")

COMMENT_STATE = len(states)
states.append("<COMMENT_STATE>")

DOUBLE_QUOTE_STRING_STATE = len(states) # TODO: string \ escaping
states.append("<DOUBLE_QUOTE_STRING>")

SIGNLE_QUOTE_STRING_STATE = len(states)
states.append("<SIGNLE_QUOTE_STRING_STATE>")


for i in range(len(states)):
    print(str(i)+":", states[i])


## letters
for char in string.ascii_lowercase + string.ascii_uppercase + "_":
    of.write("\\def\\pytexchar" + char + "{\n")
    of.write("\t\\pytexendsymboltoken\n")
    of.write("\t\\xdef\\buffer{\\buffer "+char+"}\n\t")
    ficount = 0
    for kws in keyword_states:
        if kws+char in keyword_states:
            of.write("\\ifnum \\state = " + str(states.index(kws)) + "\n")
            of.write("\t\t\\state="+str(states.index(kws+char))+"\n")
            of.write("\t\\else ")
            ficount += 1

    of.write("\\state="+str(IDENTIFIER_STATE)+"\n")

    for _ in range(ficount):
        of.write("\\fi")
    of.write("}\n\n")

## numbers
for char in "0123456789":
    of.write("\\def\\pytexchar" + specialcharnames[char] + "{\n")
    of.write("\t\\pytexendsymboltoken\n")
    of.write("\t\\xdef\\buffer{\\buffer "+char+"}\n\t")
    of.write("\t\\ifnum \\state = 0\n")
    of.write("\t\t\\state="+str(NUMBER_STATE)+"\n")
    of.write("\t\\else")
    of.write("\t\t\\state="+str(IDENTIFIER_STATE)+"\n")
    of.write("\t\\fi")
    of.write("}\n\n")

## other
for char in specialcharnames:
    if char in "0123456789#\'\" \t":
        continue
    of.write("\\def\\pytexchar" + specialcharnames[char] + "{\n")
    of.write("\t\\pytexendnametoken\n\t")
    ficount = 0
    for sym in symbol_states:
        if sym+char in symbol_states:
            of.write("\\ifnum \\state="+str(states.index(sym))+"\n")
            of.write("\t\t\\state="+str(states.index(sym+char))+"\n")
            of.write("\t\\else ")
            ficount += 1
        elif (sym in symbolnames) and (char in states):
            of.write("\\ifnum \\state="+str(states.index(sym))+"\n")
            of.write("\t\t\\pytexendsymboltoken\n")
            of.write("\t\t\\state="+str(states.index(char))+"\n")
            of.write("\t\\else ")
            ficount += 1

    of.write("\n\tERROR in parsing: unexpected '"+specialcharnames[char]+"'\\exit\n")

    for _ in range(ficount):
        of.write("\\fi")
    of.write("\n}\n\n")

## special other
of.write("""
\\def\\pytexcharNewline{
    \\pytexendsymboltoken
    \\pytexendnametoken
    \\state=0   
}

\\def\\pytexcharSpace{
    \\pytexendsymboltoken
    \\pytexendnametoken
    \\state=0   
}

\\def\\pytexcharTab{
    \\pytexendsymboltoken
    \\pytexendnametoken
    \\state=0   
}

\\def\\pytexcharDoubleQuote{
    \\pytexendsymboltoken
    \\pytexendnametoken
    \\state=""" + str(DOUBLE_QUOTE_STRING_STATE) + """
}
""")


of.write("\\def\\pytexendnametoken{\n\t")
ficount = 0
for kw in keyword.kwlist:
    of.write("\\ifnum \\state = " + str(states.index(kw)) + "\n")
    of.write("\t\t\\xdef\\tokenlist{\\tokenlist TK"+kw+"}\n")
    of.write("\t\t\\state=0\n")
    of.write("\t\t\\gdef\\buffer{}\n")
    of.write("\t\\else")
    ficount += 1
of.write("\\ifnum \\state = " + str(IDENTIFIER_STATE) + "\n")
of.write("\t\t\\xdef\\tokenlist{\\tokenlist NAME(\\buffer)}\n")
of.write("\t\t\\state=0\n")
of.write("\t\t\\gdef\\buffer{}\n")
of.write("\t\\fi")
for _ in range(ficount):
    of.write("\\fi")
of.write("\n}\n\n")


of.write("\\def\\pytexendsymboltoken{\n\t")
ficount = 0
for sym in symbolnames:
    of.write("\\ifnum \\state = " + str(states.index(sym)) + "\n")
    of.write("\t\t\\xdef\\tokenlist{\\tokenlist TK"+symbolnames[sym]+"}\n")
    of.write("\t\t\\state=0\n")
    of.write("\t\t\\gdef\\buffer{}\n")
    of.write("\t\\else")
    ficount += 1
for _ in range(ficount):
    of.write("\\fi")
of.write("\n}\n\n")


of.write("\\def\\ifdefaultbehaviour{\n")
of.write("")


of.write("\\def\\pytexcharDollar{\\pytexendnametoken\\pytexendsymboltoken\\tokenlist\n}\n")

