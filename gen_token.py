import keyword
import string
from specialcharnames import *
from symbolnames import *

DEFAULT_STATE = 0
NAME_STATE = 1
NUMBER_STATE = 2
SYMBOL_STATE = 3
COMMENT_STATE = 4
INDENT_STATE = 5

of = open("build/tokeniser.tex", "w")

of.write("% DO NOT EDIT THIS FILE DIRECTLY\n")
of.write("% This file was generated by 'gen_token.py'\n\n")

of.write("\\newcount\\state\n")
of.write("\\state="+str(INDENT_STATE)+"\n\n")

of.write("\\def\\@pytexTokeniser@buffer{}\n")
of.write("\\@pytexList@new{@pytexTokenList}\n\n")


# INDENT STUFF
of.write("\\newcount\\currentindent\n")
of.write("\\currentindent=0\n")
of.write("\\@pytexStack@new{indentStack}\n")
of.write("\\indentStack@push{0}\n\n")



# END NAME TOKEN
of.write("\\def\\@pytexTokeniser@endnametoken{\n\t")
of.write("\t\\ifnum\\state="+str(NAME_STATE)+"\n")
ficount = 0
for kw in keyword.kwlist:
    of.write("\t\t\\def\\@pytexTMP@keyword{"+kw+"}\n")
    of.write("\t\t\\ifx\\@pytexTokeniser@buffer\\@pytexTMP@keyword\n")
    of.write("\t\t\t\\@pytexTokenList@push{\\@pytexToken@"+kw+"}\n")
    of.write("\t\t\\else\n")
    ficount += 1
of.write("\t\t\t\\e\\@pytexTokenList@push\\e{\\e\\@pytexToken@Identifier\\e{\\@pytexTokeniser@buffer}}")
of.write("\n\t\t")
for _ in range(ficount):
    of.write("\\fi")
of.write("\n")
of.write("\t\t\\state=0\n")
of.write("\t\t\\gdef\\@pytexTokeniser@buffer{}\n")
of.write("\t\t\\let\\@pytexTMP@keyword\\undefined\n")
of.write("\t\\fi\n")
of.write("}\n\n")


# END NUMBER TOKEN
of.write("\\def\\@pytexTokeniser@endnumbertoken{\n")
of.write("\t\\ifnum\\state="+str(NUMBER_STATE)+"\n")
of.write("\t\t\\e\\@pytexTokenList@push\\e{\\e\\@pytexToken@Number\\e{\\@pytexTokeniser@buffer}}\n")
of.write("\t\t\\gdef\\@pytexTokeniser@buffer{}\n")
of.write("\t\t\\state=0\n")
of.write("\t\\fi\n")
of.write("}\n\n")


# DEDENT
of.write("\\def\\@pytexTokeniser@dedent{\n")
of.write("\t\\ifnum\\currentindent<\\lastindent\n")
of.write("\t\t\\@pytexTokenList@push{\\@pytexToken@Dedent}\n")
of.write("\t\t\\indentStack@popd\n")
of.write("\t\t\\indentStack@peek{\\lastindent}\n")
of.write("\t\t\\ifnum\\currentindent>\\lastindent\n")
of.write("\t\t\t\\@pytexError{IndentationError: unindent does not match any outer indentation level}\n")
of.write("\t\t\\fi\n")
of.write("\t\t\\@pytexTokeniser@dedent\n")
of.write("\t\\fi\n")
of.write("}\n\n")

# END INDENT
of.write("\\def\\@pytexTokeniser@endindent{\n")
of.write("\t\\ifnum\\state="+str(INDENT_STATE)+"\n")
of.write("\t\t\\indentStack@peek{\\lastindent}\n")
of.write("\t\t\\ifnum\\currentindent>\\lastindent\n")
of.write("\t\t\t\\e\\indentStack@push\\e{\\the\\currentindent}\n")
of.write("\t\t\t\\edef\\lastindent{\\the\\currentindent}\n")
of.write("\t\t\t\\@pytexTokenList@push{\\@pytexToken@Indent}\n")
of.write("\t\t\\fi\n")
of.write("\t\t\\@pytexTokeniser@dedent\n")
of.write("\t\t\\currentindent=0\n")
of.write("\t\t\\state=0\n")
of.write("\t\\fi\n")
of.write("}\n\n")


# END SYMBOL
of.write("\\def\\@pytexTokeniser@endsymboltoken{\n")
of.write("\t\\ifnum\\state="+str(SYMBOL_STATE)+"\n")
ficount = 0
for sym in symbolnames:
    mangled_sym = "".join([specialcharnames[x] for x in sym])
    of.write("\t\t\\def\\@pytexTMP@symbol{"+mangled_sym+"}\n")
    of.write("\t\t\\ifx\\@pytexTokeniser@buffer\\@pytexTMP@symbol\n")
    of.write("\t\t\t\\@pytexTokenList@push{\\@pytexToken@"+symbolnames[sym]+"}\n")
    of.write("\t\t\\else\n")
    ficount += 1
of.write("\t\t\\@pytexError{Tokeniser error: unknown symbol: \\@pytexTokeniser@buffer}\n")
of.write("\t\t")
for _ in range(ficount):
    of.write("\\fi")
of.write("\n")
of.write("\t\t\\state=0\n")
of.write("\t\t\\gdef\\@pytexTokeniser@buffer{}\n")
of.write("\t\t\\let\\@pytexTMP@symbol\\undefined\n")
of.write("\t\\fi\n")
of.write("}\n\n")



## letters
for char in string.ascii_lowercase + string.ascii_uppercase:
    of.write("\\def\\@pytexChar@"+char+"{\\@pytexTokeniser@letter{"+char+"}}\n")
of.write("\\def\\@pytexChar@Underscore{\\@pytexTokeniser@letter{_}}\n") # underscore is also a letter

of.write("\\def\\@pytexTokeniser@letter#1{\n")
of.write("\t\\@pytexTokeniser@endindent\n")
of.write("\t\\@pytexTokeniser@endsymboltoken\n")
of.write("\t\\ifnum\\state="+str(COMMENT_STATE)+"\\else")
of.write("\t\\ifnum\\state=0\\else\\ifnum\\state="+str(NAME_STATE)+"\\else \\@pytexError{Internal error: starting to tokenise name when not in 0 state.}\\fi\\fi")
of.write("\t\\xdef\\@pytexTokeniser@buffer{\\@pytexTokeniser@buffer #1}\n")
of.write("\t\\state="+str(NAME_STATE)+"\n")
of.write("\\fi}\n\n")



## numbers
for char in "0123456789":
    of.write("\\def\\@pytexChar@" + specialcharnames[char] + "{\\@pytexTokeniser@number{"+char+"}}\n")

of.write("\\def\\@pytexTokeniser@number#1{\n")
of.write("\t\\@pytexTokeniser@endindent\n")
of.write("\t\\@pytexTokeniser@endsymboltoken\n")
of.write("\t\\ifnum\\state="+str(COMMENT_STATE)+"\\else")
of.write("\t\\ifnum\\state="+str(NAME_STATE)+"\n")
of.write("\t\t\\@pytexTokeniser@letter{#1}\n")
of.write("\t\\else\n")
of.write("\t\t\\ifnum\\state=0\\else\\ifnum\\state="+str(NUMBER_STATE)+"\\else \\@pytexError{Internal error: starting to tokenise number when not in 0 state.}\\fi\\fi")
of.write("\t\t\\xdef\\@pytexTokeniser@buffer{\\@pytexTokeniser@buffer #1}\n")
of.write("\t\t\\state="+str(NUMBER_STATE)+"\n")
of.write("\t\\fi\n")
of.write("\\fi}\n\n")


## symbols
for char in specialcharnames:
    if char in "0123456789#\'\" \t":
        continue
    of.write("\\def\\@pytexChar@" + specialcharnames[char] + "{\\@pytexTokeniser@symbol{"+specialcharnames[char]+"}}\n")
    
of.write("\\def\\@pytexTokeniser@symbol#1{\n")
of.write("\t\\@pytexTokeniser@endnametoken\n")
of.write("\t\\@pytexTokeniser@endnumbertoken\n") # TODO: what about decimal points?
of.write("\t\\@pytexTokeniser@endindent\n")
of.write("\t\\ifnum\\state="+str(COMMENT_STATE)+"\\else")
of.write("\t\\ifnum\\state=0\\else\\ifnum\\state="+str(SYMBOL_STATE)+"\\else \\@pytexError{Internal error: starting to symbols name when not in 0 state.}\\fi\\fi")
of.write("\t\\xdef\\@pytexTokeniser@buffer{\\@pytexTokeniser@buffer #1}\n")
of.write("\t\\state="+str(SYMBOL_STATE)+"\n")
of.write("\\fi}\n")



### special other # TODO: emit indents TODO: check for space/tab indent mixing
# TODO: handling empty lines, or lines with only indents and/or comments
of.write("""
\\def\\@pytexChar@Newline{
    \\@pytexTokeniser@endnametoken
    \\@pytexTokeniser@endnumbertoken
    \\@pytexTokeniser@endindent
    \\@pytexTokeniser@endsymboltoken
    \\ifnum\\state=0\\else\\ifnum\\state="""+str(COMMENT_STATE)+"""\\else \\@pytexError{Internal error: starting to tokenise comment when not in 0 state.}\\fi\\fi
    \\state="""+str(INDENT_STATE)+"""
    \\@pytexTokenList@push{\\@pytexToken@Newline}
}

\\def\\@pytexChar@Space{
    \\@pytexTokeniser@endnametoken
    \\@pytexTokeniser@endnumbertoken
    \\@pytexTokeniser@endsymboltoken
    \\ifnum\\state="""+str(INDENT_STATE)+"""
        \\advance\\currentindent by 1
    \\fi
}

\\def\\@pytexChar@Tab{
    \\@pytexTokeniser@endnametoken
    \\@pytexTokeniser@endnumbertoken
    \\@pytexTokeniser@endsymboltoken
    \\ifnum\\state="""+str(INDENT_STATE)+"""
        \\advance\\currentindent by 1
    \\fi
}

\\def\\@pytexChar@Hash{
    \\ifnum\\state="""+str(COMMENT_STATE)+"""\\else
    \\@pytexTokeniser@endnametoken
    \\@pytexTokeniser@endnumbertoken
    \\@pytexTokeniser@endsymboltoken
    \\@pytexTokeniser@endindent
    \\ifnum\\state=0\\else \\@pytexError{Internal error: starting comment when not in 0 state.}\\fi
    \\state="""+str(COMMENT_STATE)+"""
\\fi}
""")



