import keyword
import string
from specialcharnames import *
from symbolnames import *

keyword.kwlist.append("print") # TODO: implement function calls properly

DEFAULT_STATE = 0
NAME_STATE = 1
NUMBER_STATE = 2
SYMBOL_STATE = 3
COMMENT_STATE = 4
INDENT_STATE = 5

of = open("build/tokeniser.tex", "w")

of.write("% DO NOT EDIT THIS FILE DIRECTLY\n")
of.write("% This file was generated by 'gen_token.py'\n\n")

of.write("% --- BEGIN tokeniser.tex copy ---\n")
of.write(open("src/tokeniser.tex", "r").read().split('\n',1)[1])
of.write("% --- END tokeniser.tex copy ---\n\n")

# END NAME TOKEN
of.write("\\def\\@pytexTokeniser@endnametoken{%\n\t")
of.write("\t\\ifnum\\state="+str(NAME_STATE)+"%\n")
ficount = 0
for kw in keyword.kwlist:
    of.write("\t\t\\def\\@pytexTMP@keyword{"+kw+"}%\n")
    of.write("\t\t\\ifx\\@pytexTokeniser@buffer\\@pytexTMP@keyword%\n")
    of.write("\t\t\t\\@pytexTokenList@push{\\@pytexToken@"+kw+"}%\n")
    of.write("\t\t\\else%\n")
    ficount += 1
of.write("\t\t\t\\e\\@pytexTokenList@push\\e{\\e\\@pytexToken@Identifier\\e{\\@pytexTokeniser@buffer}}%\n")
of.write("\t\t")
for _ in range(ficount):
    of.write("\\fi")
of.write("%\n")
of.write("\t\t\\state=0%\n")
of.write("\t\t\\gdef\\@pytexTokeniser@buffer{}%\n")
of.write("\t\t\\let\\@pytexTMP@keyword\\undefined%\n")
of.write("\t\\fi%\n")
of.write("}\n\n")


# END SYMBOL
of.write("\\def\\@pytexTokeniser@endsymboltoken{%\n")
of.write("\t\\ifnum\\state="+str(SYMBOL_STATE)+"%\n")
ficount = 0
for sym in symbolnames:
    mangled_sym = "".join([specialcharnames[x] for x in sym])
    of.write("\t\t\\def\\@pytexTMP@symbol{"+mangled_sym+"}%\n")
    of.write("\t\t\\ifx\\@pytexTokeniser@buffer\\@pytexTMP@symbol%\n")
    of.write("\t\t\t\\@pytexTokenList@push{\\@pytexToken@"+symbolnames[sym]+"}%\n")
    of.write("\t\t\\else%\n")
    ficount += 1
of.write("\t\t\\@pytexError{Tokeniser error: unknown symbol: \\@pytexTokeniser@buffer}%\n")
of.write("\t\t")
for _ in range(ficount):
    of.write("\\fi")
of.write("%\n")
of.write("\t\t\\state=0%\n")
of.write("\t\t\\gdef\\@pytexTokeniser@buffer{}%\n")
of.write("\t\t\\let\\@pytexTMP@symbol\\undefined%\n")
of.write("\t\\fi%\n")
of.write("}\n\n")



## letters
for char in string.ascii_lowercase + string.ascii_uppercase:
    of.write("\\def\\@pytexChar@"+char+"{\\@pytexTokeniser@letter{"+char+"}}\n")
of.write("\\def\\@pytexChar@Underscore{\\@pytexTokeniser@letter{_}}\n") # underscore is also a letter

## numbers
for char in "0123456789":
    of.write("\\def\\@pytexChar@" + specialcharnames[char] + "{\\@pytexTokeniser@number{"+char+"}}\n")

## symbols
for char in specialcharnames:
    if char in "0123456789#\'\" \t\n\r}":
        continue
    of.write("\\def\\@pytexChar@" + specialcharnames[char] + "{\\@pytexTokeniser@symbol{"+specialcharnames[char]+"}}\n")
of.write("\\def\\@pytexChar@" + specialcharnames['}'] + "{\\@pytexTokeniser@symbol{"+specialcharnames['}']+"}\\@pytexTokeniser@checkEnd}\n")


### TODO: check for space/tab indent mixing
# TODO: handling empty lines, or lines with only indents and/or comments

